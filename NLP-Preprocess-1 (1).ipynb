{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a710e425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7053cb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"text\":[\"I can't believe how amazing NLP is!\",\n",
    "           \"The quick brown for jumpover the lazy dog.\",\n",
    "           \"Data Science is an interdisciplinary field.\",\n",
    "           \"Machine Learning isn't just about algorithms.\",\n",
    "           \"Never understimate the power of human intution.\"],\n",
    "    \"label\":[0,1,0,1,0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2da4a879",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f991ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I can't believe how amazing NLP is!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The quick brown for jumpover the lazy dog.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science is an interdisciplinary field.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Machine Learning isn't just about algorithms.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Never understimate the power of human intution.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text  label\n",
       "0              I can't believe how amazing NLP is!      0\n",
       "1       The quick brown for jumpover the lazy dog.      1\n",
       "2      Data Science is an interdisciplinary field.      0\n",
       "3    Machine Learning isn't just about algorithms.      1\n",
       "4  Never understimate the power of human intution.      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b466f498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5de4672b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\JAYSURYA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a856f713",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\JAYSURYA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b35a85e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\JAYSURYA\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac7ccae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\JAYSURYA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44b5ba2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords, wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6be1416f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3a4edd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfcab1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f3136a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52756feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting contractions\n",
      "  Obtaining dependency information for contractions from https://files.pythonhosted.org/packages/bb/e4/725241b788963b460ce0118bfd5c505dd3d1bdd020ee740f9f39044ed4a7/contractions-0.1.73-py2.py3-none-any.whl.metadata\n",
      "  Downloading contractions-0.1.73-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting textsearch>=0.0.21 (from contractions)\n",
      "  Obtaining dependency information for textsearch>=0.0.21 from https://files.pythonhosted.org/packages/e2/0f/6f08dd89e9d71380a369b1f5b6c97a32d62fc9cfacc1c5b8329505b9e495/textsearch-0.0.24-py2.py3-none-any.whl.metadata\n",
      "  Downloading textsearch-0.0.24-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
      "  Obtaining dependency information for anyascii from https://files.pythonhosted.org/packages/4f/7b/a9a747e0632271d855da379532b05a62c58e979813814a57fa3b3afeb3a4/anyascii-0.3.2-py3-none-any.whl.metadata\n",
      "  Downloading anyascii-0.3.2-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
      "  Obtaining dependency information for pyahocorasick from https://files.pythonhosted.org/packages/36/76/d83c60ec7a202cbfeffaa9649d0fee6ddcb974622e411b86211ff3572549/pyahocorasick-2.1.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading pyahocorasick-2.1.0-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
      "Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
      "   ---------------------------------------- 0.0/289.9 kB ? eta -:--:--\n",
      "   --------------- ------------------------ 112.6/289.9 kB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 289.9/289.9 kB 3.6 MB/s eta 0:00:00\n",
      "Downloading pyahocorasick-2.1.0-cp311-cp311-win_amd64.whl (39 kB)\n",
      "Installing collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
      "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.1.0 textsearch-0.0.24\n"
     ]
    }
   ],
   "source": [
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "86c4392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "959e9e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(text):\n",
    "    \"\"\"Expand Contractions using contraction library\"\"\"\n",
    "    return contractions.fix(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1853e8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    \"\"\"Convert text to lowercase and remove punctuation.\"\"\"\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "091b1d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Expand_contracted']= df['text'].apply(expand_contractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d4497609",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['normalize_text']= df['Expand_contracted'].apply(normalize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b2846261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"Tokenize text into word and sentence\"\"\"\n",
    "    words = word_tokenize(text)\n",
    "    sentences = sent_tokenize(text)\n",
    "    return words, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0c44874b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['words_tokenize'], df['sent_tokenize'] = zip(*df['normalize_text'].apply(tokenize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "464fbed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>Expand_contracted</th>\n",
       "      <th>normalize_text</th>\n",
       "      <th>words_tokenize</th>\n",
       "      <th>sent_tokenize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I can't believe how amazing NLP is!</td>\n",
       "      <td>0</td>\n",
       "      <td>I cannot believe how amazing NLP is!</td>\n",
       "      <td>i cannot believe how amazing nlp is</td>\n",
       "      <td>[i, can, not, believe, how, amazing, nlp, is]</td>\n",
       "      <td>[i cannot believe how amazing nlp is]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The quick brown for jumpover the lazy dog.</td>\n",
       "      <td>1</td>\n",
       "      <td>The quick brown for jumpover the lazy dog.</td>\n",
       "      <td>the quick brown for jumpover the lazy dog</td>\n",
       "      <td>[the, quick, brown, for, jumpover, the, lazy, ...</td>\n",
       "      <td>[the quick brown for jumpover the lazy dog]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science is an interdisciplinary field.</td>\n",
       "      <td>0</td>\n",
       "      <td>Data Science is an interdisciplinary field.</td>\n",
       "      <td>data science is an interdisciplinary field</td>\n",
       "      <td>[data, science, is, an, interdisciplinary, field]</td>\n",
       "      <td>[data science is an interdisciplinary field]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Machine Learning isn't just about algorithms.</td>\n",
       "      <td>1</td>\n",
       "      <td>Machine Learning is not just about algorithms.</td>\n",
       "      <td>machine learning is not just about algorithms</td>\n",
       "      <td>[machine, learning, is, not, just, about, algo...</td>\n",
       "      <td>[machine learning is not just about algorithms]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Never understimate the power of human intution.</td>\n",
       "      <td>0</td>\n",
       "      <td>Never understimate the power of human intution.</td>\n",
       "      <td>never understimate the power of human intution</td>\n",
       "      <td>[never, understimate, the, power, of, human, i...</td>\n",
       "      <td>[never understimate the power of human intution]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text  label  \\\n",
       "0              I can't believe how amazing NLP is!      0   \n",
       "1       The quick brown for jumpover the lazy dog.      1   \n",
       "2      Data Science is an interdisciplinary field.      0   \n",
       "3    Machine Learning isn't just about algorithms.      1   \n",
       "4  Never understimate the power of human intution.      0   \n",
       "\n",
       "                                 Expand_contracted  \\\n",
       "0             I cannot believe how amazing NLP is!   \n",
       "1       The quick brown for jumpover the lazy dog.   \n",
       "2      Data Science is an interdisciplinary field.   \n",
       "3   Machine Learning is not just about algorithms.   \n",
       "4  Never understimate the power of human intution.   \n",
       "\n",
       "                                   normalize_text  \\\n",
       "0             i cannot believe how amazing nlp is   \n",
       "1       the quick brown for jumpover the lazy dog   \n",
       "2      data science is an interdisciplinary field   \n",
       "3   machine learning is not just about algorithms   \n",
       "4  never understimate the power of human intution   \n",
       "\n",
       "                                      words_tokenize  \\\n",
       "0      [i, can, not, believe, how, amazing, nlp, is]   \n",
       "1  [the, quick, brown, for, jumpover, the, lazy, ...   \n",
       "2  [data, science, is, an, interdisciplinary, field]   \n",
       "3  [machine, learning, is, not, just, about, algo...   \n",
       "4  [never, understimate, the, power, of, human, i...   \n",
       "\n",
       "                                      sent_tokenize  \n",
       "0             [i cannot believe how amazing nlp is]  \n",
       "1       [the quick brown for jumpover the lazy dog]  \n",
       "2      [data science is an interdisciplinary field]  \n",
       "3   [machine learning is not just about algorithms]  \n",
       "4  [never understimate the power of human intution]  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "73aa724e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stopwords from a list of words.\"\"\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    negations ={'not','no','never'}\n",
    "    return [word for word in words if word not in stop_words or word in negations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a7ecc605",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['remove_stopwords'] = df['words_tokenize'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e67b3a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>Expand_contracted</th>\n",
       "      <th>normalize_text</th>\n",
       "      <th>words_tokenize</th>\n",
       "      <th>sent_tokenize</th>\n",
       "      <th>remove_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I can't believe how amazing NLP is!</td>\n",
       "      <td>0</td>\n",
       "      <td>I cannot believe how amazing NLP is!</td>\n",
       "      <td>i cannot believe how amazing nlp is</td>\n",
       "      <td>[i, can, not, believe, how, amazing, nlp, is]</td>\n",
       "      <td>[i cannot believe how amazing nlp is]</td>\n",
       "      <td>[not, believe, amazing, nlp]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The quick brown for jumpover the lazy dog.</td>\n",
       "      <td>1</td>\n",
       "      <td>The quick brown for jumpover the lazy dog.</td>\n",
       "      <td>the quick brown for jumpover the lazy dog</td>\n",
       "      <td>[the, quick, brown, for, jumpover, the, lazy, ...</td>\n",
       "      <td>[the quick brown for jumpover the lazy dog]</td>\n",
       "      <td>[quick, brown, jumpover, lazy, dog]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science is an interdisciplinary field.</td>\n",
       "      <td>0</td>\n",
       "      <td>Data Science is an interdisciplinary field.</td>\n",
       "      <td>data science is an interdisciplinary field</td>\n",
       "      <td>[data, science, is, an, interdisciplinary, field]</td>\n",
       "      <td>[data science is an interdisciplinary field]</td>\n",
       "      <td>[data, science, interdisciplinary, field]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Machine Learning isn't just about algorithms.</td>\n",
       "      <td>1</td>\n",
       "      <td>Machine Learning is not just about algorithms.</td>\n",
       "      <td>machine learning is not just about algorithms</td>\n",
       "      <td>[machine, learning, is, not, just, about, algo...</td>\n",
       "      <td>[machine learning is not just about algorithms]</td>\n",
       "      <td>[machine, learning, not, algorithms]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Never understimate the power of human intution.</td>\n",
       "      <td>0</td>\n",
       "      <td>Never understimate the power of human intution.</td>\n",
       "      <td>never understimate the power of human intution</td>\n",
       "      <td>[never, understimate, the, power, of, human, i...</td>\n",
       "      <td>[never understimate the power of human intution]</td>\n",
       "      <td>[never, understimate, power, human, intution]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text  label  \\\n",
       "0              I can't believe how amazing NLP is!      0   \n",
       "1       The quick brown for jumpover the lazy dog.      1   \n",
       "2      Data Science is an interdisciplinary field.      0   \n",
       "3    Machine Learning isn't just about algorithms.      1   \n",
       "4  Never understimate the power of human intution.      0   \n",
       "\n",
       "                                 Expand_contracted  \\\n",
       "0             I cannot believe how amazing NLP is!   \n",
       "1       The quick brown for jumpover the lazy dog.   \n",
       "2      Data Science is an interdisciplinary field.   \n",
       "3   Machine Learning is not just about algorithms.   \n",
       "4  Never understimate the power of human intution.   \n",
       "\n",
       "                                   normalize_text  \\\n",
       "0             i cannot believe how amazing nlp is   \n",
       "1       the quick brown for jumpover the lazy dog   \n",
       "2      data science is an interdisciplinary field   \n",
       "3   machine learning is not just about algorithms   \n",
       "4  never understimate the power of human intution   \n",
       "\n",
       "                                      words_tokenize  \\\n",
       "0      [i, can, not, believe, how, amazing, nlp, is]   \n",
       "1  [the, quick, brown, for, jumpover, the, lazy, ...   \n",
       "2  [data, science, is, an, interdisciplinary, field]   \n",
       "3  [machine, learning, is, not, just, about, algo...   \n",
       "4  [never, understimate, the, power, of, human, i...   \n",
       "\n",
       "                                      sent_tokenize  \\\n",
       "0             [i cannot believe how amazing nlp is]   \n",
       "1       [the quick brown for jumpover the lazy dog]   \n",
       "2      [data science is an interdisciplinary field]   \n",
       "3   [machine learning is not just about algorithms]   \n",
       "4  [never understimate the power of human intution]   \n",
       "\n",
       "                                remove_stopwords  \n",
       "0                   [not, believe, amazing, nlp]  \n",
       "1            [quick, brown, jumpover, lazy, dog]  \n",
       "2      [data, science, interdisciplinary, field]  \n",
       "3           [machine, learning, not, algorithms]  \n",
       "4  [never, understimate, power, human, intution]  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54408917",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
